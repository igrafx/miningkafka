---
version: '2'

networks:
  kafka-network:


services:
  zk:
    image: confluentinc/cp-zookeeper:${CONFLUENT_PLATFORM}
    hostname: zk
    container_name: zk
    # ports:
    #   - "2181:2181" # zk port not exposed
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
      ZOOKEEPER_TICK_TIME: 2000
    volumes:
      - ./data/zookeeper-data-volume:/var/lib/zookeeper/data
      - ./data/zookeeper-log-volume:/var/lib/zookeeper/log
    restart: always
    networks:
      - kafka-network

  broker:
    image: confluentinc/cp-kafka:${CONFLUENT_PLATFORM}
    hostname: broker
    container_name: broker
    depends_on:
      - zk
    ports:
      - "29092:29092" # internal broker port not to be exposed
      - "9092:9092" # broker port tcp
      - "19092:19092"
    #      - "9101:9101" # JMX port not exposed yet
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: 'zk:2181'
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://broker:9092,PLAINTEXT_EXTERNAL://localhost:29092
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,PLAINTEXT_EXTERNAL:PLAINTEXT
      KAFKA_BOOTSTRAP_SERVERS: 'localhost:9092'
      KAFKA_INTER_BROKER_LISTENER_NAME: PLAINTEXT
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 1
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 1
      KAFKA_GROUP_INITIAL_REBALANCE_DELAY_MS: 0
      KAFKA_JMX_PORT: 9101
      KAFKA_JMX_HOSTNAME: localhost
      KAFKA_MESSAGE_MAX_BYTES: 200000000  # 200 MB
      KAFKA_REPLICA_FETCH_MAX_BYTES: 200000000
      #      KAFKA_LOG_RETENTION_HOURS: 1 # important, ne pas remplir les disques si les données sont produites en permanence
      KAFKA_HEAP_OPTS: "-Xmx256M -Xms256M"
    #      KAFKA_BROKER_ID: 1
    #      KAFKA_ZOOKEEPER_CONNECT: 'zk:2181'
    #      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT,PLAINTEXT_PRIV_HOST:PLAINTEXT
    #      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://broker:29092,PLAINTEXT_HOST://localhost:39092,PLAINTEXT_PRIV_HOST://192.168.1.128:19092
    #      KAFKA_INTER_BROKER_LISTENER_NAME: PLAINTEXT
    #      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
    #      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 1
    #      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 1
    #      KAFKA_GROUP_INITIAL_REBALANCE_DELAY_MS: 100
    #      KAFKA_JMX_PORT: 9101
    #      KAFKA_LOG_RETENTION_MINUTES: 10  # important, ne pas remplir les disques si les données sont produites en permanence
    volumes:
      - ./data/kafka-data-volume:/var/lib/kafka/data
    restart: always
    networks:
      - kafka-network

  schema-registry:
    image: confluentinc/cp-schema-registry:${CONFLUENT_PLATFORM}
    hostname: schema-registry
    container_name: schema-registry
    depends_on:
      - broker
    expose:
      - "8081"
    ports:
      - "8081:8081"
    environment:
      SCHEMA_REGISTRY_HOST_NAME: schema-registry
      SCHEMA_REGISTRY_KAFKASTORE_BOOTSTRAP_SERVERS: ${BROKERS}

    restart: always
    networks:
      - kafka-network

  connect:
    image: confluentinc/cp-kafka-connect:${CONFLUENT_PLATFORM}
    user: "0:0"  # run as root to access chrooted sftp directories
    hostname: connect
    container_name: connect
    depends_on:
      - broker
      - schema-registry
    expose:
      - "8083"
    ports:
      - "8083:8083"
    volumes:
      - ./connect-plugins:/connect-plugins
      - ./aggregation-sink-igrafx:/aggregation-sink-igrafx:rw
      - ./avatica-1.25.0.jar:/usr/share/java/kafka-connect-jdbc/avatica-1.25.0.jar
      # SFTP directories access
      - ./data/sftp/foo/upload:/sftp/foo/upload:rw  #  example data from sftp account foo
      - ./data/sftp/foo/processed:/sftp/foo/processed:rw  #  example data from sftp account foo, processed
      - ../examples/sources/input/jira:/data/jira:rw
      - ../examples/sources/input/snow:/data/snow:rw
      - ../examples/sources/error:/data/error:rw
      - ../examples/sources/processed:/data/processed:rw
    environment:
      CONNECT_BOOTSTRAP_SERVERS: ${BROKERS}
      CONNECT_REST_ADVERTISED_HOST_NAME: connect
      CONNECT_REST_PORT: 8083
      CONNECT_GROUP_ID: compose-connect-group
      CONNECT_CONFIG_STORAGE_TOPIC: docker-connect-configs
      CONNECT_CONFIG_STORAGE_REPLICATION_FACTOR: 1
      CONNECT_OFFSET_FLUSH_INTERVAL_MS: 10000
      CONNECT_OFFSET_STORAGE_TOPIC: docker-connect-offsets
      CONNECT_OFFSET_STORAGE_REPLICATION_FACTOR: 1
      CONNECT_STATUS_STORAGE_TOPIC: docker-connect-status
      CONNECT_STATUS_STORAGE_REPLICATION_FACTOR: 1
      CONNECT_KEY_CONVERTER: org.apache.kafka.connect.storage.StringConverter
      CONNECT_VALUE_CONVERTER: io.confluent.connect.avro.AvroConverter
      CONNECT_VALUE_CONVERTER_SCHEMA_REGISTRY_URL: http://schema-registry:8081
      CONNECT_INTERNAL_KEY_CONVERTER: "org.apache.kafka.connect.json.JsonConverter"
      CONNECT_INTERNAL_VALUE_CONVERTER: "org.apache.kafka.connect.json.JsonConverter"
      CONNECT_PLUGIN_PATH: "/usr/share/java,/connect-plugins,/usr/share/confluent-hub-components,/usr/share/filestream-connectors"
      CONNECT_LOG4J_LOGGERS: org.apache.zookeeper=ERROR,org.I0Itec.zkclient=ERROR,org.reflections=ERROR
      CLASSPATH: /usr/share/java/kafka-connect-jdbc/avatica-1.25.0.jar

    restart: always
    networks:
      - kafka-network

  ksqldb-server:
    image: confluentinc/cp-ksqldb-server:${CONFLUENT_PLATFORM}
    hostname: ksqldb-server
    container_name: ksqldb-server
    depends_on:
      - broker
      - schema-registry
      - connect
    expose:
      - "8088"
    # ports:
    #   - "8088:8088"
    volumes:
      - "./extensions/:/opt/ksqldb-udfs"
    environment:
      KSQL_CONFIG_DIR: "/etc/ksql"
      KSQL_BOOTSTRAP_SERVERS: ${BROKERS}
      KSQL_HOST_NAME: ksqldb-server
      KSQL_LISTENERS: "http://0.0.0.0:8088"
      KSQL_CACHE_MAX_BYTES_BUFFERING: 0
      KSQL_KSQL_SCHEMA_REGISTRY_URL: "http://schema-registry:8081"
      KSQL_KSQL_CONNECT_URL: "http://connect:8083"
      KSQL_KSQL_LOGGING_PROCESSING_TOPIC_REPLICATION_FACTOR: 1
      KSQL_KSQL_LOGGING_PROCESSING_TOPIC_AUTO_CREATE: 'true'
      KSQL_KSQL_LOGGING_PROCESSING_STREAM_AUTO_CREATE: 'true'
      KSQL_KSQL_EXTENSION_DIR: "/opt/ksqldb-udfs"
      KSQL_KSQL_STREAMS_AUTO_OFFSET_RESET: "earliest"
    #      KSQL_KSQL_SERVICE_ID: "workgroup1_"
    restart: always
    networks:
      - kafka-network

  ksqldb-cli:
    image: confluentinc/ksqldb-cli:${KSQLDB_VERSION}
    container_name: ksqldb-cli
    depends_on:
      - broker
      - connect
      - ksqldb-server
    entrypoint: /bin/sh
    tty: true
    restart: always
    networks:
      - kafka-network

  kafka-ui:
    image: provectuslabs/kafka-ui:latest
    hostname: kafka-ui
    container_name: kafka-ui
    depends_on:
      - broker
      - schema-registry
      - connect
      - ksqldb-server
    expose:
      - "9021"
    ports:
      - "9021:8080"
    environment:
      KAFKA_CLUSTERS_0_NAME: "kafka"
      KAFKA_CLUSTERS_0_BOOTSTRAPSERVERS: ${BROKERS}
      KAFKA_CLUSTERS_0_ZOOKEEPER: 'zk:2181'
      KAFKA_CLUSTERS_0_KSQLDBSERVER: "http://ksqldb-server:8088"
      KAFKA_CLUSTERS_0_SCHEMAREGISTRY: "http://schema-registry:8081"
      KAFKA_CLUSTERS_0_SCHEMANAMETEMPLATE: "%s-value"
      KAFKA_CLUSTERS_0_KAFKACONNECT_0_NAME: "kafka connect"
      KAFKA_CLUSTERS_0_KAFKACONNECT_0_ADDRESS: 'http://connect:8083'
      AUTH_TYPE: "LOGIN_FORM"
      JAVA_OPTS: "-Dspring.security.user.name=admin -Dspring.security.user.password=admin"
    networks:
      - kafka-network


  # Optionnel : postgres pour transformations intermédiaires
  data-transform:
    image: postgres:14
    hostname: data-transform
    container_name: data-transform
    expose:
      - "5432"
    ports:
      - "5432:5432"
    environment:
      #Your database name
      POSTGRES_DB: ${POSTGRES_DB}
      POSTGRES_USER: ${POSTGRES_USER}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD}
    volumes:
      - ./data/postgres-data-transform:/var/lib/postgresql/data:rw
      - ./conf/pg-initdb.d:/docker-entrypoint-initdb.d
    networks:
      - kafka-network
    restart: always

  # Optionnel : serveur sftp pour upload de fichiers
  sftp:
    image: corilus/sftp
    volumes:
      - ./data/sftp/foo/upload:/home/foo/upload
      - ./data/sftp/foo/processed:/home/foo/processed:ro
      # please read https://github.com/Corilus/sftp#providing-your-own-ssh-host-key-recommended
      - ./conf/sftp/ssh_host_ed25519_key:/etc/ssh/ssh_host_ed25519_key:Z # https://docs.docker.com/storage/bind-mounts/#configure-the-selinux-label
      - ./conf/sftp/ssh_host_rsa_key:/etc/ssh/ssh_host_rsa_key:Z
    ports:
      - "2222:22"
    command: foo:pass:1001
    restart: always



  ###########################
  # Reverse proxy for HTTPS #
  ###########################

  nginx:
    image: nginx
    hostname: nginx
    container_name: nginx
    ports:
      - "443:443"   # ui, api
      - "80:80"     # ui
    restart: always
    networks:
      - kafka-network
    extra_hosts:
      - "host.docker.internal:172.17.0.1"   #  ip addr  show docker0 | grep inet # on host
    volumes:
      # - type: bind
      #   source: ./logs/nginx/access.log
      #   target: /var/log/nginx/host_access.log
      # - type: bind
      #   source: ./logs/nginx/error.log
      #   target: /var/log/nginx/host_error.log
      - ./nginx-proxy/certificates:/etc/ssl/docker:ro
      - ./nginx-proxy/conf/nginx.conf:/etc/nginx/nginx.conf:ro
      - ./nginx-proxy/conf/dhparam:/etc/nginx/dhparam:ro
      - ./nginx-proxy/conf/ssl.conf:/etc/nginx/ssl.conf:ro
      - ./nginx-proxy/templates/:/etc/nginx/templates/:ro
    # Be careful not to define environment variables that conflicts with nginx variables.
    # For example, defining a variable named upstream with value 'test' would cause nginx
    #   to tranform configuration like this:
    #       set $upstream "broker:8082";
    #       proxy_pass http://$upstream;
    #
    #   to that:
    #       set test "broker:8082";
    #       proxy_pass http://test;
    #
    # Which would prevent nginx container to start as 'set test ...' is not a valid syntax.
    #
    # List of variables that shouldn't be defined as they are used in configuration now:
    #   http_host
    #   proxy_add_x_forwarded_for
    #   remote_addr
    #   request_uri
    #   scheme
    #   upstream
    #   uri
    #
    # The complete list of nginx variable that could be used is available here:
    # https://nginx.org/en/docs/varindex.html
    #
    # One way of avoiding conflicts is to never define environment variables in
    # lowercase, as all Nginx variables are lowercase.
    environment:
      - NGINX_HOST=${HOST}
      - WORKGROUP_ID=${WORKGROUP_ID}
